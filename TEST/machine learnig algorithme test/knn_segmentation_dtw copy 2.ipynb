{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AZA-NWcOdz9U"
      },
      "outputs": [],
      "source": [
        "def count_values(arr):\n",
        "  unique_values, counts = np.unique(arr, return_counts=True)\n",
        "\n",
        "  # Print the unique values and their frequencies\n",
        "  for value, count in zip(unique_values, counts):\n",
        "      print(f\"{value}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AN4ZUexAwJQZ"
      },
      "outputs": [],
      "source": [
        "def split_data_balanced(X, y, test_size=0.2, random_state=None):\n",
        "    # Find unique labels and their counts\n",
        "    unique_labels, label_counts = np.unique(y, return_counts=True)\n",
        "\n",
        "    # Find the minimum label count\n",
        "    min_label_count = np.min(label_counts)\n",
        "\n",
        "    # Split the data for each label, ensuring balanced classes in the test set\n",
        "    X_train, X_test, y_train, y_test = [], [], [], []\n",
        "    for label in unique_labels:\n",
        "        # Split the data for the current label\n",
        "        X_label = X[y == label]\n",
        "        y_label = y[y == label]\n",
        "        X_label_train, X_label_test, y_label_train, y_label_test = train_test_split(\n",
        "            X_label, y_label, test_size=test_size, random_state=random_state\n",
        "        )\n",
        "\n",
        "        # Add the split data to the overall train and test sets\n",
        "        X_train.append(X_label_train)\n",
        "        X_test.append(X_label_test)\n",
        "        y_train.append(y_label_train)\n",
        "        y_test.append(y_label_test)\n",
        "\n",
        "    # Concatenate the data from all labels\n",
        "    X_train = np.concatenate(X_train)\n",
        "    X_test = np.concatenate(X_test)\n",
        "    y_train = np.concatenate(y_train)\n",
        "    y_test = np.concatenate(y_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cpSVGSCFeUXJ"
      },
      "outputs": [],
      "source": [
        "def segmantation(X,y,window_length=36 ,step_size=1):\n",
        "      # Define sliding window parameters\n",
        "      window_length = 36  # Length of each segment\n",
        "      step_size = 1  # Amount of overlap between segments\n",
        "      # Segment the time series data with sliding window\n",
        "      segments = []\n",
        "      labels = []\n",
        "\n",
        "      for i in range(0, len(X) - window_length, step_size):\n",
        "          segment = X[i:i+window_length]\n",
        "          segments.append(segment)\n",
        "          \n",
        "          # Assign label to the segment based on the presence of anomalies\n",
        "          segment_labels = y[i:i+window_length]\n",
        "          if np.any(segment_labels == 1):\n",
        "              label = 1  # Anomaly present\n",
        "          else:\n",
        "              label = 0  # No anomaly\n",
        "          labels.append(label)\n",
        "\n",
        "      # Convert segments and labels to numpy arrays\n",
        "      segments = np.array(segments)\n",
        "      labels = np.array(labels)\n",
        "      return segments,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_CMjyV-2eOM0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "file_path =r\"C:\\Users\\hp\\Desktop\\M2\\PFE\\Code\\code pfe\\Coud source\\Code\\machine learnig algorithme test\\data_kick.xlsx\"\n",
        "df=pd.read_excel(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vdrF6yn2ecJO"
      },
      "outputs": [],
      "source": [
        "X = df[[ 'TVA (m3)', 'SPPA (kPa)', 'MFOP ((m3/s)/(m3/s))', 'GASA (mol/mol)']]\n",
        "y = df['STATUS']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRW0vaXqsoWx",
        "outputId": "35c5b643-ce22-4f12-9bf5-bdc5a52423b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Int64Index([14571, 14572, 14573, 14574, 14575, 14576, 14577, 14578, 14579,\n",
              "            14580,\n",
              "            ...\n",
              "            53240, 53241, 53242, 53243, 53244, 53245, 53246, 53247, 53248,\n",
              "            53249],\n",
              "           dtype='int64', length=1238)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['STATUS']==1].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "o4ryF2GzeeUb"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "# Select the columns to normalize\n",
        "# Perform the min-max normalization\n",
        "X= scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jyRh-v1oePnp"
      },
      "outputs": [],
      "source": [
        "window=36\n",
        "segments,labels= segmantation(X,y,window_length=window ,step_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qutqq9NejJ9",
        "outputId": "945b8842-36d3-4fef-f7ca-5b550dd56cec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(42570, 36, 4) (10644, 36, 4)\n",
            "(42570, 144) (10644, 144)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = split_data_balanced(segments, labels, test_size=0.2)\n",
        "print(X_train.shape,X_test.shape)\n",
        "# Reshape the feature matrices for SVM\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "print(X_train.shape,X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEPDHdLkelkG",
        "outputId": "652e3db6-a00d-48e3-e294-be89fbacf007"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 10354\n",
            "1: 290\n",
            "0: 41413\n",
            "1: 1157\n"
          ]
        }
      ],
      "source": [
        "count_values(y_test)\n",
        "count_values(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "jXCWzmZLepbV",
        "outputId": "e5b3378a-e764-4967-b380-35acbf7b754b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&lt;function dtw at 0x000001B5E6D52E80&gt;, n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&lt;function dtw at 0x000001B5E6D52E80&gt;, n_neighbors=3)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(metric=<function dtw at 0x000001B5E6D52E80>, n_neighbors=3)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tslearn.metrics import dtw\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "knn = KNeighborsClassifier(n_neighbors=3,metric=dtw)\n",
        "knn.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "n6lZulh6vGY3"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_prd=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(2000,3000): \n",
        "    y_pred = knn.predict(X_test[i-1:i])\n",
        "    y_prd.append(y_pred[0])\n",
        "    # print(i,i-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKD27MRAfpTE",
        "outputId": "8e536ca3-5ee3-477d-d57d-3ffe67257700"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 1000\n"
          ]
        }
      ],
      "source": [
        "count_values(y_prd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_actual=y_test[2000:3000]\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score,roc_auc_score\n",
        "\n",
        "print(confusion_matrix(y_actual,y_prd))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual,y_prd))\n",
        "print(\"Precision:\", precision_score(y_actual,y_prd))\n",
        "print(\"Recall:\", recall_score(y_actual,y_prd))\n",
        "print(\"F1 Score:\",f1_score(y_actual,y_prd))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25Pazu0KytXB",
        "outputId": "b3f1450b-1660-4687-aad4-b1d676761df3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1000]]\n",
            "Accuracy: 1.0\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
          ]
        }
      ],
      "source": [
        "y_actual=y_test[7000:8000]\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score,roc_auc_score\n",
        "\n",
        "print(confusion_matrix(y_actual,y_prd))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual,y_prd))\n",
        "print(\"Precision:\", precision_score(y_actual,y_prd))\n",
        "print(\"Recall:\", recall_score(y_actual,y_prd))\n",
        "print(\"F1 Score:\",f1_score(y_actual,y_prd))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 1000\n"
          ]
        }
      ],
      "source": [
        "count_values(y_actual)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCZCO7Cc0D67"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Nu9s8Kqmz-X3"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39;49mpredict(X_test)\n",
            "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:234\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict the class labels for the provided data.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[0;32m    220\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39m    Class labels for each data sample.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    232\u001b[0m     \u001b[39m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[39m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     neigh_ind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkneighbors(X, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    235\u001b[0m     neigh_dist \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:861\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m         kwds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 861\u001b[0m     chunked_results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m    862\u001b[0m         pairwise_distances_chunked(\n\u001b[0;32m    863\u001b[0m             X,\n\u001b[0;32m    864\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_X,\n\u001b[0;32m    865\u001b[0m             reduce_func\u001b[39m=\u001b[39mreduce_func,\n\u001b[0;32m    866\u001b[0m             metric\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffective_metric_,\n\u001b[0;32m    867\u001b[0m             n_jobs\u001b[39m=\u001b[39mn_jobs,\n\u001b[0;32m    868\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_method \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mball_tree\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkd_tree\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    873\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X):\n",
            "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1867\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1866\u001b[0m     X_chunk \u001b[39m=\u001b[39m X[sl]\n\u001b[1;32m-> 1867\u001b[0m D_chunk \u001b[39m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[39m=\u001b[39;49mmetric, n_jobs\u001b[39m=\u001b[39;49mn_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m   1868\u001b[0m \u001b[39mif\u001b[39;00m (X \u001b[39mis\u001b[39;00m Y \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[39m.\u001b[39mget(\n\u001b[0;32m   1869\u001b[0m     metric, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m ) \u001b[39mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   1871\u001b[0m     \u001b[39m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   1872\u001b[0m     \u001b[39m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   1873\u001b[0m     D_chunk\u001b[39m.\u001b[39mflat[sl\u001b[39m.\u001b[39mstart :: _num_samples(X) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:2039\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msquareform(distance\u001b[39m.\u001b[39mpdist(X, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[0;32m   2037\u001b[0m     func \u001b[39m=\u001b[39m partial(distance\u001b[39m.\u001b[39mcdist, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m-> 2039\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
            "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1579\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1576\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1578\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m-> 1579\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m   1581\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1582\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
            "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1623\u001b[0m, in \u001b[0;36m_pairwise_callable\u001b[1;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1621\u001b[0m     iterator \u001b[39m=\u001b[39m itertools\u001b[39m.\u001b[39mproduct(\u001b[39mrange\u001b[39m(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), \u001b[39mrange\u001b[39m(Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]))\n\u001b[0;32m   1622\u001b[0m     \u001b[39mfor\u001b[39;00m i, j \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m-> 1623\u001b[0m         out[i, j] \u001b[39m=\u001b[39m metric(X[i], Y[j], \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m   1625\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
            "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tslearn\\metrics\\dtw_variants.py:479\u001b[0m, in \u001b[0;36mdtw\u001b[1;34m(s1, s2, global_constraint, sakoe_chiba_radius, itakura_max_slope)\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll input time series must have the same feature size.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    474\u001b[0m mask \u001b[39m=\u001b[39m compute_mask(\n\u001b[0;32m    475\u001b[0m     s1, s2,\n\u001b[0;32m    476\u001b[0m     GLOBAL_CONSTRAINT_CODE[global_constraint],\n\u001b[0;32m    477\u001b[0m     sakoe_chiba_radius\u001b[39m=\u001b[39msakoe_chiba_radius,\n\u001b[0;32m    478\u001b[0m     itakura_max_slope\u001b[39m=\u001b[39mitakura_max_slope)\n\u001b[1;32m--> 479\u001b[0m \u001b[39mreturn\u001b[39;00m njit_dtw(s1, s2, mask\u001b[39m=\u001b[39;49mmask)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "y_pred = knn.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bktYOseVw-u3",
        "outputId": "f58beb86-6714-4fea-b5a1-b1cc86f7e45a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[10342    12]\n",
            " [   95   195]]\n",
            "Accuracy: 0.9899473881999249\n",
            "Precision: 0.9420289855072463\n",
            "Recall: 0.6724137931034483\n",
            "F1 Score: 0.7847082494969819\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score,roc_auc_score\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test,y_pred))\n",
        "print(\"Precision:\", precision_score(y_test,y_pred))\n",
        "print(\"Recall:\", recall_score(y_test,y_pred))\n",
        "print(\"F1 Score:\",f1_score(y_test,y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Physical CPU cores: 4\n",
            "Logical CPU cores: 4\n",
            "Total memory: 7.20 GB\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "\n",
        "# CPU information\n",
        "cpu_count = psutil.cpu_count(logical=False)  # Number of physical CPU cores\n",
        "logical_cpu_count = psutil.cpu_count(logical=True)  # Number of logical CPU cores\n",
        "\n",
        "# Memory information\n",
        "memory_info = psutil.virtual_memory()\n",
        "total_memory = memory_info.total / (1024**3)  # Total memory in GB\n",
        "\n",
        "print(f\"Physical CPU cores: {cpu_count}\")\n",
        "print(f\"Logical CPU cores: {logical_cpu_count}\")\n",
        "print(f\"Total memory: {total_memory:.2f} GB\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
