{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AZA-NWcOdz9U"
      },
      "outputs": [],
      "source": [
        "def count_values(arr):\n",
        "  unique_values, counts = np.unique(arr, return_counts=True)\n",
        "\n",
        "  # Print the unique values and their frequencies\n",
        "  for value, count in zip(unique_values, counts):\n",
        "      print(f\"{value}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AN4ZUexAwJQZ"
      },
      "outputs": [],
      "source": [
        "def split_data_balanced(X, y, test_size=0.2, random_state=None):\n",
        "    # Find unique labels and their counts\n",
        "    unique_labels, label_counts = np.unique(y, return_counts=True)\n",
        "\n",
        "    # Find the minimum label count\n",
        "    min_label_count = np.min(label_counts)\n",
        "\n",
        "    # Split the data for each label, ensuring balanced classes in the test set\n",
        "    X_train, X_test, y_train, y_test = [], [], [], []\n",
        "    for label in unique_labels:\n",
        "        # Split the data for the current label\n",
        "        X_label = X[y == label]\n",
        "        y_label = y[y == label]\n",
        "        X_label_train, X_label_test, y_label_train, y_label_test = train_test_split(\n",
        "            X_label, y_label, test_size=test_size, random_state=random_state\n",
        "        )\n",
        "\n",
        "        # Add the split data to the overall train and test sets\n",
        "        X_train.append(X_label_train)\n",
        "        X_test.append(X_label_test)\n",
        "        y_train.append(y_label_train)\n",
        "        y_test.append(y_label_test)\n",
        "\n",
        "    # Concatenate the data from all labels\n",
        "    X_train = np.concatenate(X_train)\n",
        "    X_test = np.concatenate(X_test)\n",
        "    y_train = np.concatenate(y_train)\n",
        "    y_test = np.concatenate(y_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "cpSVGSCFeUXJ"
      },
      "outputs": [],
      "source": [
        "def segmantation(X,y,window_length=36 ):\n",
        "      step_size=1\n",
        "      # Define sliding window parameters\n",
        "     # Length of each segment\n",
        "      step_size = 1  # Amount of overlap between segments\n",
        "      # Segment the time series data with sliding window\n",
        "      segments = []\n",
        "      labels = []\n",
        "\n",
        "      for i in range(0, len(X) - window_length, step_size):\n",
        "          segment = X[i:i+window_length]\n",
        "          segments.append(segment)\n",
        "          \n",
        "          # Assign label to the segment based on the presence of anomalies\n",
        "          segment_labels = y[i:i+window_length]\n",
        "          if np.any(segment_labels == 1):\n",
        "              label = 1  # Anomaly present\n",
        "          else:\n",
        "              label = 0  # No anomaly\n",
        "          labels.append(label)\n",
        "\n",
        "      # Convert segments and labels to numpy arrays\n",
        "      segments = np.array(segments)\n",
        "      labels = np.array(labels)\n",
        "      return segments,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_CMjyV-2eOM0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "file_path =r\"C:\\Users\\hp\\Desktop\\M2\\PFE\\Code\\code pfe\\Coud source\\Code\\machine learnig algorithme test\\data_kick.xlsx\"\n",
        "df=pd.read_excel(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "vdrF6yn2ecJO"
      },
      "outputs": [],
      "source": [
        "X = df[[ 'TVA (m3)', 'SPPA (kPa)', 'MFOP ((m3/s)/(m3/s))', 'GASA (mol/mol)']][0:37]\n",
        "y = df['STATUS'][0:37]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRW0vaXqsoWx",
        "outputId": "35c5b643-ce22-4f12-9bf5-bdc5a52423b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Int64Index([14571, 14572, 14573, 14574, 14575, 14576, 14577, 14578, 14579,\n",
              "            14580,\n",
              "            ...\n",
              "            53240, 53241, 53242, 53243, 53244, 53245, 53246, 53247, 53248,\n",
              "            53249],\n",
              "           dtype='int64', length=1238)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['STATUS']==1].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TVA (m3)</th>\n",
              "      <th>SPPA (kPa)</th>\n",
              "      <th>MFOP ((m3/s)/(m3/s))</th>\n",
              "      <th>GASA (mol/mol)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39.2</td>\n",
              "      <td>82.737088</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39.2</td>\n",
              "      <td>68.947573</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>39.2</td>\n",
              "      <td>68.947573</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>39.1</td>\n",
              "      <td>68.947573</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>39.2</td>\n",
              "      <td>68.947573</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>39.2</td>\n",
              "      <td>75.842330</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>39.1</td>\n",
              "      <td>62.052816</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>39.2</td>\n",
              "      <td>68.947573</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>39.1</td>\n",
              "      <td>75.842330</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>39.2</td>\n",
              "      <td>68.947573</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>39.2</td>\n",
              "      <td>75.842330</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>39.2</td>\n",
              "      <td>75.842330</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>39.2</td>\n",
              "      <td>82.737088</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>39.2</td>\n",
              "      <td>75.842330</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>39.2</td>\n",
              "      <td>68.947573</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>39.1</td>\n",
              "      <td>68.947573</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>39.2</td>\n",
              "      <td>75.842330</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>39.2</td>\n",
              "      <td>62.052816</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>39.1</td>\n",
              "      <td>68.947573</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>39.2</td>\n",
              "      <td>68.947573</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>39.1</td>\n",
              "      <td>62.052816</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>39.1</td>\n",
              "      <td>75.842330</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>39.2</td>\n",
              "      <td>75.842330</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>39.2</td>\n",
              "      <td>68.947573</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>39.1</td>\n",
              "      <td>75.842330</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>39.2</td>\n",
              "      <td>75.842330</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>39.2</td>\n",
              "      <td>62.052816</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>39.2</td>\n",
              "      <td>68.947573</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>39.1</td>\n",
              "      <td>75.842330</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>39.2</td>\n",
              "      <td>75.842330</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>39.2</td>\n",
              "      <td>75.842330</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>39.2</td>\n",
              "      <td>68.947573</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>39.1</td>\n",
              "      <td>75.842330</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>39.1</td>\n",
              "      <td>75.842330</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>39.2</td>\n",
              "      <td>75.842330</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>39.2</td>\n",
              "      <td>55.158058</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>39.2</td>\n",
              "      <td>82.737088</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    TVA (m3)  SPPA (kPa)  MFOP ((m3/s)/(m3/s))  GASA (mol/mol)\n",
              "0       39.2   82.737088                  0.05             0.0\n",
              "1       39.2   68.947573                  0.05             0.0\n",
              "2       39.2   68.947573                  0.05             0.0\n",
              "3       39.1   68.947573                  0.05             0.0\n",
              "4       39.2   68.947573                  0.05             0.0\n",
              "5       39.2   75.842330                  0.05             0.0\n",
              "6       39.1   62.052816                  0.05             0.0\n",
              "7       39.2   68.947573                  0.05             0.0\n",
              "8       39.1   75.842330                  0.05             0.0\n",
              "9       39.2   68.947573                  0.05             0.0\n",
              "10      39.2   75.842330                  0.05             0.0\n",
              "11      39.2   75.842330                  0.05             0.0\n",
              "12      39.2   82.737088                  0.05             0.0\n",
              "13      39.2   75.842330                  0.05             0.0\n",
              "14      39.2   68.947573                  0.05             0.0\n",
              "15      39.1   68.947573                  0.05             0.0\n",
              "16      39.2   75.842330                  0.05             0.0\n",
              "17      39.2   62.052816                  0.05             0.0\n",
              "18      39.1   68.947573                  0.05             0.0\n",
              "19      39.2   68.947573                  0.05             0.0\n",
              "20      39.1   62.052816                  0.05             0.0\n",
              "21      39.1   75.842330                  0.05             0.0\n",
              "22      39.2   75.842330                  0.05             0.0\n",
              "23      39.2   68.947573                  0.05             0.0\n",
              "24      39.1   75.842330                  0.05             0.0\n",
              "25      39.2   75.842330                  0.05             0.0\n",
              "26      39.2   62.052816                  0.05             0.0\n",
              "27      39.2   68.947573                  0.05             0.0\n",
              "28      39.1   75.842330                  0.05             0.0\n",
              "29      39.2   75.842330                  0.05             0.0\n",
              "30      39.2   75.842330                  0.05             0.0\n",
              "31      39.2   68.947573                  0.05             0.0\n",
              "32      39.1   75.842330                  0.05             0.0\n",
              "33      39.1   75.842330                  0.05             0.0\n",
              "34      39.2   75.842330                  0.05             0.0\n",
              "35      39.2   55.158058                  0.05             0.0\n",
              "36      39.2   82.737088                  0.05             0.0"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "o4ryF2GzeeUb"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "# Select the columns to normalize\n",
        "# Perform the min-max normalization\n",
        "X= scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "jyRh-v1oePnp"
      },
      "outputs": [],
      "source": [
        "window=36\n",
        "segments,labels= segmantation(X,y,window_length=window )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3.92000000e+01, 8.27370875e+01, 5.00000000e-02, 0.00000000e+00])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qutqq9NejJ9",
        "outputId": "945b8842-36d3-4fef-f7ca-5b550dd56cec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(42570, 36, 4) (10644, 36, 4)\n",
            "(42570, 144) (10644, 144)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = split_data_balanced(segments, labels, test_size=0.2)\n",
        "print(X_train.shape,X_test.shape)\n",
        "# Reshape the feature matrices for SVM\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "print(X_train.shape,X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEPDHdLkelkG",
        "outputId": "652e3db6-a00d-48e3-e294-be89fbacf007"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 10354\n",
            "1: 290\n",
            "0: 41413\n",
            "1: 1157\n"
          ]
        }
      ],
      "source": [
        "count_values(y_test)\n",
        "count_values(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Om5PjVDTfb1v"
      },
      "outputs": [],
      "source": [
        "pip install tslearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "jXCWzmZLepbV",
        "outputId": "e5b3378a-e764-4967-b380-35acbf7b754b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&lt;function dtw at 0x000001EB47A2EFC0&gt;, n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&lt;function dtw at 0x000001EB47A2EFC0&gt;, n_neighbors=3)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(metric=<function dtw at 0x000001EB47A2EFC0>, n_neighbors=3)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tslearn.metrics import dtw\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "knn = KNeighborsClassifier(n_neighbors=3,metric=dtw)\n",
        "knn.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['C:\\\\Users\\\\hp\\\\Desktop\\\\M2\\\\PFE\\\\Code\\\\code pfe\\\\Coud source\\\\Code\\\\Saved models\\\\knn_model.pkl']"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "filename =r'C:\\Users\\hp\\Desktop\\M2\\PFE\\Code\\code pfe\\Coud source\\Code\\Saved models\\knn_model.pkl'\n",
        "joblib.dump(knn, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVB0RDaLp720",
        "outputId": "b1d0817d-f2b6-4ae8-e293-f391a3817054"
      },
      "outputs": [],
      "source": [
        "loaded_model = joblib.load(filename)\n",
        "predictions = loaded_model.predict(X_test[1:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "n6lZulh6vGY3"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_prd=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10643 10642\n",
            "10642 10641\n",
            "10641 10640\n",
            "10640 10639\n",
            "10639 10638\n",
            "10638 10637\n",
            "10637 10636\n",
            "10636 10635\n",
            "10635 10634\n",
            "10634 10633\n",
            "10633 10632\n",
            "10632 10631\n",
            "10631 10630\n",
            "10630 10629\n",
            "10629 10628\n",
            "10628 10627\n",
            "10627 10626\n",
            "10626 10625\n",
            "10625 10624\n",
            "10624 10623\n",
            "10623 10622\n",
            "10622 10621\n",
            "10621 10620\n",
            "10620 10619\n",
            "10619 10618\n",
            "10618 10617\n",
            "10617 10616\n",
            "10616 10615\n",
            "10615 10614\n",
            "10614 10613\n",
            "10613 10612\n",
            "10612 10611\n",
            "10611 10610\n",
            "10610 10609\n",
            "10609 10608\n",
            "10608 10607\n",
            "10607 10606\n",
            "10606 10605\n",
            "10605 10604\n",
            "10604 10603\n",
            "10603 10602\n",
            "10602 10601\n",
            "10601 10600\n",
            "10600 10599\n",
            "10599 10598\n",
            "10598 10597\n",
            "10597 10596\n",
            "10596 10595\n",
            "10595 10594\n",
            "10594 10593\n",
            "10593 10592\n",
            "10592 10591\n",
            "10591 10590\n",
            "10590 10589\n",
            "10589 10588\n",
            "10588 10587\n",
            "10587 10586\n",
            "10586 10585\n",
            "10585 10584\n",
            "10584 10583\n",
            "10583 10582\n",
            "10582 10581\n",
            "10581 10580\n",
            "10580 10579\n",
            "10579 10578\n",
            "10578 10577\n",
            "10577 10576\n",
            "10576 10575\n",
            "10575 10574\n",
            "10574 10573\n",
            "10573 10572\n",
            "10572 10571\n",
            "10571 10570\n",
            "10570 10569\n",
            "10569 10568\n",
            "10568 10567\n",
            "10567 10566\n",
            "10566 10565\n",
            "10565 10564\n",
            "10564 10563\n",
            "10563 10562\n",
            "10562 10561\n",
            "10561 10560\n",
            "10560 10559\n",
            "10559 10558\n",
            "10558 10557\n",
            "10557 10556\n",
            "10556 10555\n",
            "10555 10554\n",
            "10554 10553\n",
            "10553 10552\n",
            "10552 10551\n",
            "10551 10550\n",
            "10550 10549\n",
            "10549 10548\n",
            "10548 10547\n",
            "10547 10546\n",
            "10546 10545\n",
            "10545 10544\n",
            "10544 10543\n",
            "10543 10542\n",
            "10542 10541\n",
            "10541 10540\n",
            "10540 10539\n",
            "10539 10538\n",
            "10538 10537\n",
            "10537 10536\n",
            "10536 10535\n",
            "10535 10534\n",
            "10534 10533\n",
            "10533 10532\n",
            "10532 10531\n",
            "10531 10530\n",
            "10530 10529\n",
            "10529 10528\n",
            "10528 10527\n",
            "10527 10526\n",
            "10526 10525\n",
            "10525 10524\n",
            "10524 10523\n",
            "10523 10522\n",
            "10522 10521\n",
            "10521 10520\n",
            "10520 10519\n",
            "10519 10518\n",
            "10518 10517\n",
            "10517 10516\n",
            "10516 10515\n",
            "10515 10514\n",
            "10514 10513\n",
            "10513 10512\n",
            "10512 10511\n",
            "10511 10510\n",
            "10510 10509\n",
            "10509 10508\n",
            "10508 10507\n",
            "10507 10506\n",
            "10506 10505\n",
            "10505 10504\n",
            "10504 10503\n",
            "10503 10502\n",
            "10502 10501\n",
            "10501 10500\n",
            "10500 10499\n",
            "10499 10498\n",
            "10498 10497\n",
            "10497 10496\n",
            "10496 10495\n",
            "10495 10494\n",
            "10494 10493\n",
            "10493 10492\n",
            "10492 10491\n",
            "10491 10490\n",
            "10490 10489\n",
            "10489 10488\n",
            "10488 10487\n",
            "10487 10486\n",
            "10486 10485\n",
            "10485 10484\n",
            "10484 10483\n",
            "10483 10482\n",
            "10482 10481\n",
            "10481 10480\n",
            "10480 10479\n",
            "10479 10478\n",
            "10478 10477\n",
            "10477 10476\n",
            "10476 10475\n",
            "10475 10474\n",
            "10474 10473\n",
            "10473 10472\n",
            "10472 10471\n",
            "10471 10470\n",
            "10470 10469\n",
            "10469 10468\n",
            "10468 10467\n",
            "10467 10466\n",
            "10466 10465\n",
            "10465 10464\n",
            "10464 10463\n",
            "10463 10462\n",
            "10462 10461\n",
            "10461 10460\n",
            "10460 10459\n",
            "10459 10458\n",
            "10458 10457\n",
            "10457 10456\n",
            "10456 10455\n",
            "10455 10454\n",
            "10454 10453\n",
            "10453 10452\n",
            "10452 10451\n",
            "10451 10450\n",
            "10450 10449\n",
            "10449 10448\n",
            "10448 10447\n",
            "10447 10446\n",
            "10446 10445\n",
            "10445 10444\n",
            "10444 10443\n",
            "10443 10442\n",
            "10442 10441\n",
            "10441 10440\n",
            "10440 10439\n",
            "10439 10438\n",
            "10438 10437\n",
            "10437 10436\n",
            "10436 10435\n",
            "10435 10434\n",
            "10434 10433\n",
            "10433 10432\n",
            "10432 10431\n",
            "10431 10430\n",
            "10430 10429\n",
            "10429 10428\n",
            "10428 10427\n",
            "10427 10426\n",
            "10426 10425\n",
            "10425 10424\n",
            "10424 10423\n",
            "10423 10422\n",
            "10422 10421\n",
            "10421 10420\n",
            "10420 10419\n",
            "10419 10418\n",
            "10418 10417\n",
            "10417 10416\n",
            "10416 10415\n",
            "10415 10414\n",
            "10414 10413\n",
            "10413 10412\n",
            "10412 10411\n",
            "10411 10410\n",
            "10410 10409\n",
            "10409 10408\n",
            "10408 10407\n",
            "10407 10406\n",
            "10406 10405\n",
            "10405 10404\n",
            "10404 10403\n",
            "10403 10402\n",
            "10402 10401\n",
            "10401 10400\n",
            "10400 10399\n",
            "10399 10398\n",
            "10398 10397\n",
            "10397 10396\n",
            "10396 10395\n",
            "10395 10394\n",
            "10394 10393\n",
            "10393 10392\n",
            "10392 10391\n",
            "10391 10390\n",
            "10390 10389\n",
            "10389 10388\n",
            "10388 10387\n",
            "10387 10386\n",
            "10386 10385\n",
            "10385 10384\n",
            "10384 10383\n",
            "10383 10382\n",
            "10382 10381\n",
            "10381 10380\n",
            "10380 10379\n",
            "10379 10378\n",
            "10378 10377\n",
            "10377 10376\n",
            "10376 10375\n",
            "10375 10374\n",
            "10374 10373\n",
            "10373 10372\n",
            "10372 10371\n",
            "10371 10370\n",
            "10370 10369\n",
            "10369 10368\n",
            "10368 10367\n",
            "10367 10366\n",
            "10366 10365\n",
            "10365 10364\n",
            "10364 10363\n",
            "10363 10362\n",
            "10362 10361\n",
            "10361 10360\n",
            "10360 10359\n",
            "10359 10358\n",
            "10358 10357\n",
            "10357 10356\n",
            "10356 10355\n",
            "10355 10354\n",
            "10354 10353\n",
            "10353 10352\n",
            "10352 10351\n",
            "10351 10350\n",
            "10350 10349\n",
            "10349 10348\n",
            "10348 10347\n",
            "10347 10346\n",
            "10346 10345\n",
            "10345 10344\n",
            "10344 10343\n",
            "10343 10342\n",
            "10342 10341\n",
            "10341 10340\n",
            "10340 10339\n",
            "10339 10338\n",
            "10338 10337\n",
            "10337 10336\n",
            "10336 10335\n",
            "10335 10334\n",
            "10334 10333\n",
            "10333 10332\n",
            "10332 10331\n",
            "10331 10330\n",
            "10330 10329\n",
            "10329 10328\n",
            "10328 10327\n",
            "10327 10326\n",
            "10326 10325\n",
            "10325 10324\n",
            "10324 10323\n",
            "10323 10322\n",
            "10322 10321\n",
            "10321 10320\n",
            "10320 10319\n",
            "10319 10318\n",
            "10318 10317\n",
            "10317 10316\n",
            "10316 10315\n",
            "10315 10314\n",
            "10314 10313\n",
            "10313 10312\n",
            "10312 10311\n",
            "10311 10310\n",
            "10310 10309\n",
            "10309 10308\n",
            "10308 10307\n",
            "10307 10306\n",
            "10306 10305\n",
            "10305 10304\n",
            "10304 10303\n",
            "10303 10302\n",
            "10302 10301\n",
            "10301 10300\n",
            "10300 10299\n",
            "10299 10298\n",
            "10298 10297\n",
            "10297 10296\n",
            "10296 10295\n",
            "10295 10294\n",
            "10294 10293\n",
            "10293 10292\n",
            "10292 10291\n",
            "10291 10290\n",
            "10290 10289\n",
            "10289 10288\n",
            "10288 10287\n",
            "10287 10286\n",
            "10286 10285\n",
            "10285 10284\n",
            "10284 10283\n",
            "10283 10282\n",
            "10282 10281\n",
            "10281 10280\n",
            "10280 10279\n",
            "10279 10278\n",
            "10278 10277\n",
            "10277 10276\n",
            "10276 10275\n",
            "10275 10274\n",
            "10274 10273\n",
            "10273 10272\n",
            "10272 10271\n",
            "10271 10270\n",
            "10270 10269\n",
            "10269 10268\n",
            "10268 10267\n",
            "10267 10266\n",
            "10266 10265\n",
            "10265 10264\n",
            "10264 10263\n",
            "10263 10262\n",
            "10262 10261\n",
            "10261 10260\n",
            "10260 10259\n",
            "10259 10258\n",
            "10258 10257\n",
            "10257 10256\n",
            "10256 10255\n",
            "10255 10254\n",
            "10254 10253\n",
            "10253 10252\n",
            "10252 10251\n",
            "10251 10250\n",
            "10250 10249\n",
            "10249 10248\n",
            "10248 10247\n",
            "10247 10246\n",
            "10246 10245\n",
            "10245 10244\n",
            "10244 10243\n",
            "10243 10242\n",
            "10242 10241\n",
            "10241 10240\n",
            "10240 10239\n",
            "10239 10238\n",
            "10238 10237\n",
            "10237 10236\n",
            "10236 10235\n",
            "10235 10234\n",
            "10234 10233\n",
            "10233 10232\n",
            "10232 10231\n",
            "10231 10230\n",
            "10230 10229\n",
            "10229 10228\n",
            "10228 10227\n",
            "10227 10226\n",
            "10226 10225\n",
            "10225 10224\n",
            "10224 10223\n",
            "10223 10222\n",
            "10222 10221\n",
            "10221 10220\n",
            "10220 10219\n",
            "10219 10218\n",
            "10218 10217\n",
            "10217 10216\n",
            "10216 10215\n",
            "10215 10214\n",
            "10214 10213\n",
            "10213 10212\n",
            "10212 10211\n",
            "10211 10210\n",
            "10210 10209\n",
            "10209 10208\n",
            "10208 10207\n",
            "10207 10206\n",
            "10206 10205\n",
            "10205 10204\n",
            "10204 10203\n",
            "10203 10202\n",
            "10202 10201\n",
            "10201 10200\n",
            "10200 10199\n",
            "10199 10198\n",
            "10198 10197\n",
            "10197 10196\n",
            "10196 10195\n",
            "10195 10194\n",
            "10194 10193\n",
            "10193 10192\n",
            "10192 10191\n",
            "10191 10190\n",
            "10190 10189\n",
            "10189 10188\n",
            "10188 10187\n",
            "10187 10186\n",
            "10186 10185\n",
            "10185 10184\n",
            "10184 10183\n",
            "10183 10182\n",
            "10182 10181\n",
            "10181 10180\n",
            "10180 10179\n",
            "10179 10178\n",
            "10178 10177\n",
            "10177 10176\n",
            "10176 10175\n",
            "10175 10174\n",
            "10174 10173\n",
            "10173 10172\n",
            "10172 10171\n",
            "10171 10170\n",
            "10170 10169\n",
            "10169 10168\n",
            "10168 10167\n",
            "10167 10166\n",
            "10166 10165\n",
            "10165 10164\n",
            "10164 10163\n",
            "10163 10162\n",
            "10162 10161\n",
            "10161 10160\n",
            "10160 10159\n",
            "10159 10158\n",
            "10158 10157\n",
            "10157 10156\n",
            "10156 10155\n",
            "10155 10154\n",
            "10154 10153\n",
            "10153 10152\n",
            "10152 10151\n",
            "10151 10150\n",
            "10150 10149\n",
            "10149 10148\n",
            "10148 10147\n",
            "10147 10146\n",
            "10146 10145\n",
            "10145 10144\n",
            "10144 10143\n",
            "10143 10142\n",
            "10142 10141\n",
            "10141 10140\n",
            "10140 10139\n",
            "10139 10138\n",
            "10138 10137\n",
            "10137 10136\n",
            "10136 10135\n",
            "10135 10134\n",
            "10134 10133\n",
            "10133 10132\n",
            "10132 10131\n",
            "10131 10130\n",
            "10130 10129\n",
            "10129 10128\n",
            "10128 10127\n",
            "10127 10126\n",
            "10126 10125\n",
            "10125 10124\n",
            "10124 10123\n",
            "10123 10122\n",
            "10122 10121\n",
            "10121 10120\n",
            "10120 10119\n",
            "10119 10118\n",
            "10118 10117\n",
            "10117 10116\n",
            "10116 10115\n",
            "10115 10114\n",
            "10114 10113\n",
            "10113 10112\n",
            "10112 10111\n",
            "10111 10110\n",
            "10110 10109\n",
            "10109 10108\n",
            "10108 10107\n",
            "10107 10106\n",
            "10106 10105\n",
            "10105 10104\n",
            "10104 10103\n",
            "10103 10102\n",
            "10102 10101\n",
            "10101 10100\n",
            "10100 10099\n",
            "10099 10098\n",
            "10098 10097\n",
            "10097 10096\n",
            "10096 10095\n",
            "10095 10094\n",
            "10094 10093\n",
            "10093 10092\n",
            "10092 10091\n",
            "10091 10090\n",
            "10090 10089\n",
            "10089 10088\n",
            "10088 10087\n",
            "10087 10086\n",
            "10086 10085\n",
            "10085 10084\n",
            "10084 10083\n",
            "10083 10082\n",
            "10082 10081\n",
            "10081 10080\n",
            "10080 10079\n",
            "10079 10078\n",
            "10078 10077\n",
            "10077 10076\n",
            "10076 10075\n",
            "10075 10074\n",
            "10074 10073\n",
            "10073 10072\n",
            "10072 10071\n",
            "10071 10070\n",
            "10070 10069\n",
            "10069 10068\n",
            "10068 10067\n",
            "10067 10066\n",
            "10066 10065\n",
            "10065 10064\n",
            "10064 10063\n",
            "10063 10062\n",
            "10062 10061\n",
            "10061 10060\n",
            "10060 10059\n",
            "10059 10058\n",
            "10058 10057\n",
            "10057 10056\n",
            "10056 10055\n",
            "10055 10054\n",
            "10054 10053\n",
            "10053 10052\n",
            "10052 10051\n",
            "10051 10050\n",
            "10050 10049\n",
            "10049 10048\n",
            "10048 10047\n",
            "10047 10046\n",
            "10046 10045\n",
            "10045 10044\n",
            "10044 10043\n",
            "10043 10042\n",
            "10042 10041\n",
            "10041 10040\n",
            "10040 10039\n",
            "10039 10038\n",
            "10038 10037\n",
            "10037 10036\n",
            "10036 10035\n",
            "10035 10034\n",
            "10034 10033\n",
            "10033 10032\n",
            "10032 10031\n",
            "10031 10030\n",
            "10030 10029\n",
            "10029 10028\n",
            "10028 10027\n",
            "10027 10026\n",
            "10026 10025\n",
            "10025 10024\n",
            "10024 10023\n",
            "10023 10022\n",
            "10022 10021\n",
            "10021 10020\n",
            "10020 10019\n",
            "10019 10018\n",
            "10018 10017\n",
            "10017 10016\n",
            "10016 10015\n",
            "10015 10014\n",
            "10014 10013\n",
            "10013 10012\n",
            "10012 10011\n",
            "10011 10010\n",
            "10010 10009\n",
            "10009 10008\n",
            "10008 10007\n",
            "10007 10006\n",
            "10006 10005\n",
            "10005 10004\n",
            "10004 10003\n",
            "10003 10002\n",
            "10002 10001\n",
            "10001 10000\n",
            "10000 9999\n",
            "9999 9998\n",
            "9998 9997\n",
            "9997 9996\n",
            "9996 9995\n",
            "9995 9994\n",
            "9994 9993\n",
            "9993 9992\n",
            "9992 9991\n",
            "9991 9990\n",
            "9990 9989\n",
            "9989 9988\n",
            "9988 9987\n",
            "9987 9986\n",
            "9986 9985\n",
            "9985 9984\n",
            "9984 9983\n",
            "9983 9982\n",
            "9982 9981\n",
            "9981 9980\n",
            "9980 9979\n",
            "9979 9978\n",
            "9978 9977\n",
            "9977 9976\n",
            "9976 9975\n",
            "9975 9974\n",
            "9974 9973\n",
            "9973 9972\n",
            "9972 9971\n",
            "9971 9970\n",
            "9970 9969\n",
            "9969 9968\n",
            "9968 9967\n",
            "9967 9966\n",
            "9966 9965\n",
            "9965 9964\n",
            "9964 9963\n",
            "9963 9962\n",
            "9962 9961\n",
            "9961 9960\n",
            "9960 9959\n",
            "9959 9958\n",
            "9958 9957\n",
            "9957 9956\n",
            "9956 9955\n",
            "9955 9954\n",
            "9954 9953\n",
            "9953 9952\n",
            "9952 9951\n",
            "9951 9950\n",
            "9950 9949\n",
            "9949 9948\n",
            "9948 9947\n",
            "9947 9946\n",
            "9946 9945\n",
            "9945 9944\n",
            "9944 9943\n",
            "9943 9942\n",
            "9942 9941\n",
            "9941 9940\n",
            "9940 9939\n",
            "9939 9938\n",
            "9938 9937\n",
            "9937 9936\n",
            "9936 9935\n",
            "9935 9934\n",
            "9934 9933\n",
            "9933 9932\n",
            "9932 9931\n",
            "9931 9930\n",
            "9930 9929\n",
            "9929 9928\n",
            "9928 9927\n",
            "9927 9926\n",
            "9926 9925\n",
            "9925 9924\n",
            "9924 9923\n",
            "9923 9922\n",
            "9922 9921\n",
            "9921 9920\n",
            "9920 9919\n",
            "9919 9918\n",
            "9918 9917\n",
            "9917 9916\n",
            "9916 9915\n",
            "9915 9914\n",
            "9914 9913\n",
            "9913 9912\n",
            "9912 9911\n",
            "9911 9910\n",
            "9910 9909\n",
            "9909 9908\n",
            "9908 9907\n",
            "9907 9906\n",
            "9906 9905\n",
            "9905 9904\n",
            "9904 9903\n",
            "9903 9902\n",
            "9902 9901\n",
            "9901 9900\n",
            "9900 9899\n",
            "9899 9898\n",
            "9898 9897\n",
            "9897 9896\n",
            "9896 9895\n",
            "9895 9894\n",
            "9894 9893\n",
            "9893 9892\n",
            "9892 9891\n",
            "9891 9890\n",
            "9890 9889\n",
            "9889 9888\n",
            "9888 9887\n",
            "9887 9886\n",
            "9886 9885\n",
            "9885 9884\n",
            "9884 9883\n",
            "9883 9882\n",
            "9882 9881\n",
            "9881 9880\n",
            "9880 9879\n",
            "9879 9878\n",
            "9878 9877\n",
            "9877 9876\n",
            "9876 9875\n",
            "9875 9874\n",
            "9874 9873\n",
            "9873 9872\n",
            "9872 9871\n",
            "9871 9870\n",
            "9870 9869\n",
            "9869 9868\n",
            "9868 9867\n",
            "9867 9866\n",
            "9866 9865\n",
            "9865 9864\n",
            "9864 9863\n",
            "9863 9862\n",
            "9862 9861\n",
            "9861 9860\n",
            "9860 9859\n",
            "9859 9858\n",
            "9858 9857\n",
            "9857 9856\n",
            "9856 9855\n",
            "9855 9854\n",
            "9854 9853\n",
            "9853 9852\n",
            "9852 9851\n",
            "9851 9850\n",
            "9850 9849\n",
            "9849 9848\n",
            "9848 9847\n",
            "9847 9846\n",
            "9846 9845\n",
            "9845 9844\n",
            "9844 9843\n",
            "9843 9842\n",
            "9842 9841\n",
            "9841 9840\n",
            "9840 9839\n",
            "9839 9838\n",
            "9838 9837\n",
            "9837 9836\n",
            "9836 9835\n",
            "9835 9834\n",
            "9834 9833\n",
            "9833 9832\n",
            "9832 9831\n",
            "9831 9830\n",
            "9830 9829\n",
            "9829 9828\n",
            "9828 9827\n",
            "9827 9826\n",
            "9826 9825\n",
            "9825 9824\n",
            "9824 9823\n",
            "9823 9822\n",
            "9822 9821\n",
            "9821 9820\n",
            "9820 9819\n",
            "9819 9818\n",
            "9818 9817\n",
            "9817 9816\n",
            "9816 9815\n",
            "9815 9814\n",
            "9814 9813\n",
            "9813 9812\n",
            "9812 9811\n",
            "9811 9810\n",
            "9810 9809\n",
            "9809 9808\n",
            "9808 9807\n",
            "9807 9806\n",
            "9806 9805\n",
            "9805 9804\n",
            "9804 9803\n",
            "9803 9802\n",
            "9802 9801\n",
            "9801 9800\n",
            "9800 9799\n",
            "9799 9798\n",
            "9798 9797\n",
            "9797 9796\n",
            "9796 9795\n",
            "9795 9794\n",
            "9794 9793\n",
            "9793 9792\n",
            "9792 9791\n",
            "9791 9790\n",
            "9790 9789\n",
            "9789 9788\n",
            "9788 9787\n",
            "9787 9786\n",
            "9786 9785\n",
            "9785 9784\n",
            "9784 9783\n",
            "9783 9782\n",
            "9782 9781\n",
            "9781 9780\n",
            "9780 9779\n",
            "9779 9778\n",
            "9778 9777\n",
            "9777 9776\n",
            "9776 9775\n",
            "9775 9774\n",
            "9774 9773\n",
            "9773 9772\n",
            "9772 9771\n",
            "9771 9770\n",
            "9770 9769\n",
            "9769 9768\n",
            "9768 9767\n",
            "9767 9766\n",
            "9766 9765\n",
            "9765 9764\n",
            "9764 9763\n",
            "9763 9762\n",
            "9762 9761\n",
            "9761 9760\n",
            "9760 9759\n",
            "9759 9758\n",
            "9758 9757\n",
            "9757 9756\n",
            "9756 9755\n",
            "9755 9754\n",
            "9754 9753\n",
            "9753 9752\n",
            "9752 9751\n",
            "9751 9750\n",
            "9750 9749\n",
            "9749 9748\n",
            "9748 9747\n",
            "9747 9746\n",
            "9746 9745\n",
            "9745 9744\n",
            "9744 9743\n",
            "9743 9742\n",
            "9742 9741\n",
            "9741 9740\n",
            "9740 9739\n",
            "9739 9738\n",
            "9738 9737\n",
            "9737 9736\n",
            "9736 9735\n",
            "9735 9734\n",
            "9734 9733\n",
            "9733 9732\n",
            "9732 9731\n",
            "9731 9730\n",
            "9730 9729\n",
            "9729 9728\n",
            "9728 9727\n",
            "9727 9726\n",
            "9726 9725\n",
            "9725 9724\n",
            "9724 9723\n",
            "9723 9722\n",
            "9722 9721\n",
            "9721 9720\n",
            "9720 9719\n",
            "9719 9718\n",
            "9718 9717\n",
            "9717 9716\n",
            "9716 9715\n",
            "9715 9714\n",
            "9714 9713\n",
            "9713 9712\n",
            "9712 9711\n",
            "9711 9710\n",
            "9710 9709\n",
            "9709 9708\n",
            "9708 9707\n",
            "9707 9706\n",
            "9706 9705\n",
            "9705 9704\n",
            "9704 9703\n",
            "9703 9702\n",
            "9702 9701\n",
            "9701 9700\n",
            "9700 9699\n",
            "9699 9698\n",
            "9698 9697\n",
            "9697 9696\n",
            "9696 9695\n",
            "9695 9694\n",
            "9694 9693\n",
            "9693 9692\n",
            "9692 9691\n",
            "9691 9690\n",
            "9690 9689\n",
            "9689 9688\n",
            "9688 9687\n",
            "9687 9686\n",
            "9686 9685\n",
            "9685 9684\n",
            "9684 9683\n",
            "9683 9682\n",
            "9682 9681\n",
            "9681 9680\n",
            "9680 9679\n",
            "9679 9678\n",
            "9678 9677\n",
            "9677 9676\n",
            "9676 9675\n",
            "9675 9674\n",
            "9674 9673\n",
            "9673 9672\n",
            "9672 9671\n",
            "9671 9670\n",
            "9670 9669\n",
            "9669 9668\n",
            "9668 9667\n",
            "9667 9666\n",
            "9666 9665\n",
            "9665 9664\n",
            "9664 9663\n",
            "9663 9662\n",
            "9662 9661\n",
            "9661 9660\n",
            "9660 9659\n",
            "9659 9658\n",
            "9658 9657\n",
            "9657 9656\n",
            "9656 9655\n",
            "9655 9654\n",
            "9654 9653\n",
            "9653 9652\n",
            "9652 9651\n",
            "9651 9650\n",
            "9650 9649\n",
            "9649 9648\n",
            "9648 9647\n",
            "9647 9646\n",
            "9646 9645\n",
            "9645 9644\n",
            "9644 9643\n",
            "9643 9642\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(y_test) - 1,9642 , -1): \n",
        "    y_pred = knn.predict(X_test[i-1:i])\n",
        "    y_prd.append(y_pred[0])\n",
        "    print(i,i-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKD27MRAfpTE",
        "outputId": "8e536ca3-5ee3-477d-d57d-3ffe67257700"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 794\n",
            "1: 207\n"
          ]
        }
      ],
      "source": [
        "count_values(y_prd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "yprd=y_prd[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1001"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y_prd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25Pazu0KytXB",
        "outputId": "b3f1450b-1660-4687-aad4-b1d676761df3"
      },
      "outputs": [],
      "source": [
        "y_actual=y_test[9643:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 711\n",
            "1: 290\n"
          ]
        }
      ],
      "source": [
        "count_values(y_actual)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "VCZCO7Cc0D67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[708   3]\n",
            " [ 86 204]]\n",
            "Accuracy: 0.9110889110889111\n",
            "Precision: 0.9855072463768116\n",
            "Recall: 0.7034482758620689\n",
            "F1 Score: 0.8209255533199196\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score,roc_auc_score\n",
        "\n",
        "print(confusion_matrix(y_actual,yprd))\n",
        "print(\"Accuracy:\", accuracy_score(y_actual,yprd))\n",
        "print(\"Precision:\", precision_score(y_actual,yprd))\n",
        "print(\"Recall:\", recall_score(y_actual,yprd))\n",
        "print(\"F1 Score:\",f1_score(y_actual,yprd))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "Nu9s8Kqmz-X3"
      },
      "outputs": [],
      "source": [
        "y_pred = knn.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bktYOseVw-u3",
        "outputId": "f58beb86-6714-4fea-b5a1-b1cc86f7e45a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[10342    12]\n",
            " [   95   195]]\n",
            "Accuracy: 0.9899473881999249\n",
            "Precision: 0.9420289855072463\n",
            "Recall: 0.6724137931034483\n",
            "F1 Score: 0.7847082494969819\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score,roc_auc_score\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test,y_pred))\n",
        "print(\"Precision:\", precision_score(y_test,y_pred))\n",
        "print(\"Recall:\", recall_score(y_test,y_pred))\n",
        "print(\"F1 Score:\",f1_score(y_test,y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HirGlMIIl4C5",
        "outputId": "f60462e7-ceb8-4ce4-f02d-cbf0163167bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(42594, 4) (10649, 4)\n",
            "(42594, 4) (10649, 4)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "print(X_train.shape,X_test.shape)\n",
        "# Reshape the feature matrices for SVM\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "print(X_train.shape,X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbvcCj56hlSE"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "def dtw_distance(ts1, ts2, window):\n",
        "    \"\"\"\n",
        "    Computes the DTW distance between two time series with a given window.\n",
        "    \"\"\"\n",
        "    n1, n2 = len(ts1), len(ts2)\n",
        "    w = np.max([window, abs(n1 - n2)])\n",
        "    dtw = np.full((n1 + 1, n2 + 1), np.inf)\n",
        "    dtw[0, 0] = 0\n",
        "    for i in range(1, n1 + 1):\n",
        "        for j in range(np.max([1, i - w]), np.min([n2, i + w]) + 1):\n",
        "            cost = abs(ts1[i - 1] - ts2[j - 1])\n",
        "            dtw[i, j] = cost + np.min([dtw[i - 1, j], dtw[i, j - 1], dtw[i - 1, j - 1]])\n",
        "    return dtw[-1, -1]\n",
        "\n",
        "# Define the kNN classifier with the custom DTW distance metric\n",
        "knn = KNeighborsClassifier(n_neighbors=5, metric=lambda x, y: dtw_distance(x, y, window=36))\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "wnGgREeSiKqf",
        "outputId": "3459ed5f-25f4-4b6a-be62-e86e2acec195"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&lt;function &lt;lambda&gt; at 0x7f2120c9b0a0&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&lt;function &lt;lambda&gt; at 0x7f2120c9b0a0&gt;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(metric=<function <lambda> at 0x7f2120c9b0a0>)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b51NlLx0m9tL",
        "outputId": "0cad7bc2-de71-4c23-d22d-af8fed56d4b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10649,)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "twevuAbYiSp7"
      },
      "outputs": [],
      "source": [
        "# Make predictions on new data\n",
        "y_pred = knn.predict(X_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
