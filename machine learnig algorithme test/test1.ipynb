{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_3540\\3096263500.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_data = merged_data.append(df[cols][:x], ignore_index=True)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_3540\\3096263500.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_data = merged_data.append(df[cols][:x], ignore_index=True)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_3540\\3096263500.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_data = merged_data.append(df[cols][:x], ignore_index=True)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_3540\\3096263500.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_data = merged_data.append(df[cols][:x], ignore_index=True)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_3540\\3096263500.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_data = merged_data.append(df[cols][:x], ignore_index=True)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_3540\\3096263500.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_data = merged_data.append(df[cols][:x], ignore_index=True)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_3540\\3096263500.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  merged_data = merged_data.append(df[cols][:x], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.DataFrame()\n",
    "path = r'C:\\Users\\hp\\Desktop\\M2\\PFE\\Code\\code pfe\\dataset'\n",
    "files = ['6.xlsx',\n",
    "         '8.xlsx',\n",
    "         '15.xlsx',\n",
    "         '17.xlsx',\n",
    "         '19.xlsx',\n",
    "         '26.xlsx',\n",
    "         '29.xlsx']\n",
    "cols=['index','TVA (m3)', 'SPPA (kPa)',\n",
    "       'MFOP ((m3/s)/(m3/s))', 'GASA (mol/mol)','STATUS','id']\n",
    "for i in files:\n",
    "    df=pd.read_excel(path+'\\\\'+i)\n",
    "    df['id']=i[1]\n",
    "    x=max(df[df['STATUS']==1].index)\n",
    "    merged_data = merged_data.append(df[cols][:x], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_excel('data_kick.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110737, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df=pd.read_excel(r'C:\\Users\\hp\\Desktop\\M2\\PFE\\Code\\code pfe\\dataset\\all_data.xlsx')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106256\n"
     ]
    }
   ],
   "source": [
    "print(max(df[df['STATUS']==1].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12652\\1002051947.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['index'] = pd.to_datetime(df['index'],format='%d/%m/%Y, %H:%M:%S')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.rename(columns={'index': 'time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['TVA (m3)', 'SPPA (kPa)',\n",
    "       'MFOP ((m3/s)/(m3/s))', 'GASA (mol/mol)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17280 entries, 0 to 17279\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   time                  17280 non-null  datetime64[ns]\n",
      " 1   TVA (m3)              17280 non-null  float64       \n",
      " 2   SPPA (kPa)            17280 non-null  float64       \n",
      " 3   MFOP ((m3/s)/(m3/s))  17280 non-null  float64       \n",
      " 4   GASA (mol/mol)        17280 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4)\n",
      "memory usage: 675.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69120 entries, 0 to 69119\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   id         69120 non-null  int64         \n",
      " 1   time       69120 non-null  datetime64[ns]\n",
      " 2   attribute  69120 non-null  object        \n",
      " 3   value      69120 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(1)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "\n",
    "\n",
    "# Add a constant 'id' column for the single well\n",
    "data['id'] = 1\n",
    "\n",
    "# Convert your data to long format\n",
    "long_data = data.melt(id_vars=[\"id\", \"time\"], var_name=\"attribute\", value_name=\"value\")\n",
    "\n",
    "long_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction:   0%|          | 0/4 [06:54<?, ?it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.45 GiB for an array with shape (17279, 17279, 2) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\utilities\\distribution.py\", line 43, in _function_with_partly_reduce\n    results = list(itertools.chain.from_iterable(results))\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\utilities\\distribution.py\", line 42, in <genexpr>\n    results = (map_function(chunk, **kwargs) for chunk in chunk_list)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py\", line 386, in _do_extraction_on_chunk\n    return list(_f())\n           ^^^^^^^^^^\n  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py\", line 374, in _f\n    for key, item in result:\n  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py\", line 368, in <genexpr>\n    (convert_to_output_format(param), func(x, **param))\n                                      ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\feature_extraction\\feature_calculators.py\", line 1790, in approximate_entropy\n    return np.abs(_phi(m) - _phi(m + 1))\n                  ^^^^^^^\n  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\feature_extraction\\feature_calculators.py\", line 1785, in _phi\n    np.max(np.abs(x_re[:, np.newaxis] - x_re[np.newaxis, :]), axis=2) <= r,\n                  ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 4.45 GiB for an array with shape (17279, 17279, 2) and data type float64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Extract features using tsfresh\u001b[39;00m\n\u001b[0;32m      2\u001b[0m extraction_settings \u001b[39m=\u001b[39m ComprehensiveFCParameters()\n\u001b[1;32m----> 3\u001b[0m extracted_features \u001b[39m=\u001b[39m extract_features(long_data, column_id\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m\"\u001b[39;49m, column_sort\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m\"\u001b[39;49m, column_kind\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mattribute\u001b[39;49m\u001b[39m\"\u001b[39;49m, column_value\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m, default_fc_parameters\u001b[39m=\u001b[39;49mextraction_settings)\n\u001b[0;32m      5\u001b[0m \u001b[39m# Impute missing values in the extracted features\u001b[39;00m\n\u001b[0;32m      6\u001b[0m imputed_features \u001b[39m=\u001b[39m impute(extracted_features)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py:164\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(timeseries_container, default_fc_parameters, kind_to_fc_parameters, column_id, column_sort, column_kind, column_value, chunksize, n_jobs, show_warnings, disable_progressbar, impute_function, profile, profiling_filename, profiling_sorting, distributor, pivot)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 164\u001b[0m result \u001b[39m=\u001b[39m _do_extraction(\n\u001b[0;32m    165\u001b[0m     df\u001b[39m=\u001b[39;49mtimeseries_container,\n\u001b[0;32m    166\u001b[0m     column_id\u001b[39m=\u001b[39;49mcolumn_id,\n\u001b[0;32m    167\u001b[0m     column_value\u001b[39m=\u001b[39;49mcolumn_value,\n\u001b[0;32m    168\u001b[0m     column_kind\u001b[39m=\u001b[39;49mcolumn_kind,\n\u001b[0;32m    169\u001b[0m     column_sort\u001b[39m=\u001b[39;49mcolumn_sort,\n\u001b[0;32m    170\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    171\u001b[0m     chunk_size\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m    172\u001b[0m     disable_progressbar\u001b[39m=\u001b[39;49mdisable_progressbar,\n\u001b[0;32m    173\u001b[0m     show_warnings\u001b[39m=\u001b[39;49mshow_warnings,\n\u001b[0;32m    174\u001b[0m     default_fc_parameters\u001b[39m=\u001b[39;49mdefault_fc_parameters,\n\u001b[0;32m    175\u001b[0m     kind_to_fc_parameters\u001b[39m=\u001b[39;49mkind_to_fc_parameters,\n\u001b[0;32m    176\u001b[0m     distributor\u001b[39m=\u001b[39;49mdistributor,\n\u001b[0;32m    177\u001b[0m     pivot\u001b[39m=\u001b[39;49mpivot,\n\u001b[0;32m    178\u001b[0m )\n\u001b[0;32m    180\u001b[0m \u001b[39m# Impute the result if requested\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[39mif\u001b[39;00m impute_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py:294\u001b[0m, in \u001b[0;36m_do_extraction\u001b[1;34m(df, column_id, column_value, column_kind, column_sort, default_fc_parameters, kind_to_fc_parameters, n_jobs, chunk_size, disable_progressbar, show_warnings, distributor, pivot)\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mthe passed distributor is not an DistributorBaseClass object\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    288\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[0;32m    289\u001b[0m     default_fc_parameters\u001b[39m=\u001b[39mdefault_fc_parameters,\n\u001b[0;32m    290\u001b[0m     kind_to_fc_parameters\u001b[39m=\u001b[39mkind_to_fc_parameters,\n\u001b[0;32m    291\u001b[0m     show_warnings\u001b[39m=\u001b[39mshow_warnings,\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 294\u001b[0m result \u001b[39m=\u001b[39m distributor\u001b[39m.\u001b[39;49mmap_reduce(\n\u001b[0;32m    295\u001b[0m     _do_extraction_on_chunk,\n\u001b[0;32m    296\u001b[0m     data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m    297\u001b[0m     chunk_size\u001b[39m=\u001b[39;49mchunk_size,\n\u001b[0;32m    298\u001b[0m     function_kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[0;32m    299\u001b[0m )\n\u001b[0;32m    301\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m pivot:\n\u001b[0;32m    302\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\utilities\\distribution.py:241\u001b[0m, in \u001b[0;36mIterableDistributorBaseClass.map_reduce\u001b[1;34m(self, map_function, data, function_kwargs, chunk_size, data_length)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     result \u001b[39m=\u001b[39m (\n\u001b[0;32m    236\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute(\n\u001b[0;32m    237\u001b[0m             _function_with_partly_reduce, chunk_generator, map_kwargs\n\u001b[0;32m    238\u001b[0m         ),\n\u001b[0;32m    239\u001b[0m     )\n\u001b[1;32m--> 241\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mchain\u001b[39m.\u001b[39;49mfrom_iterable(result))\n\u001b[0;32m    243\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    245\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:873\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n\u001b[1;32m--> 873\u001b[0m \u001b[39mraise\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[1;34m()\u001b[0m\n\u001b[0;32m    123\u001b[0m job, i, func, args, kwds \u001b[39m=\u001b[39m task\n\u001b[0;32m    124\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 125\u001b[0m     result \u001b[39m=\u001b[39m (\u001b[39mTrue\u001b[39;00m, func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[0;32m    126\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    127\u001b[0m     \u001b[39mif\u001b[39;00m wrap_exception \u001b[39mand\u001b[39;00m func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _helper_reraises_exception:\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\utilities\\distribution.py:43\u001b[0m, in \u001b[0;36m_function_with_partly_reduce\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m kwargs \u001b[39m=\u001b[39m kwargs \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m     42\u001b[0m results \u001b[39m=\u001b[39m (map_function(chunk, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunk_list)\n\u001b[1;32m---> 43\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(itertools\u001b[39m.\u001b[39mchain\u001b[39m.\u001b[39mfrom_iterable(results))\n\u001b[0;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\utilities\\distribution.py:42\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39mSmall helper function to call a function (map_function)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39mon a list of data chunks (chunk_list) and convert the results into\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39m:rtype: list\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m kwargs \u001b[39m=\u001b[39m kwargs \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m---> 42\u001b[0m results \u001b[39m=\u001b[39m (map_function(chunk, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunk_list)\n\u001b[0;32m     43\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(itertools\u001b[39m.\u001b[39mchain\u001b[39m.\u001b[39mfrom_iterable(results))\n\u001b[0;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py:386\u001b[0m, in \u001b[0;36m_do_extraction_on_chunk\u001b[1;34m()\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m     warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 386\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_f())\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py:374\u001b[0m, in \u001b[0;36m_f\u001b[1;34m()\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    372\u001b[0m         result \u001b[39m=\u001b[39m [(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, func(x))]\n\u001b[1;32m--> 374\u001b[0m \u001b[39mfor\u001b[39;00m key, item \u001b[39min\u001b[39;00m result:\n\u001b[0;32m    375\u001b[0m     feature_name \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(kind) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    376\u001b[0m     \u001b[39mif\u001b[39;00m key:\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py:368\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    366\u001b[0m     \u001b[39mif\u001b[39;00m parameter_list:\n\u001b[0;32m    367\u001b[0m         result \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 368\u001b[0m             (convert_to_output_format(param), func(x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparam))\n\u001b[0;32m    369\u001b[0m             \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m parameter_list\n\u001b[0;32m    370\u001b[0m         )\n\u001b[0;32m    371\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    372\u001b[0m         result \u001b[39m=\u001b[39m [(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, func(x))]\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\feature_extraction\\feature_calculators.py:1790\u001b[0m, in \u001b[0;36mapproximate_entropy\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1784\u001b[0m     C \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(\n\u001b[0;32m   1785\u001b[0m         np\u001b[39m.\u001b[39mmax(np\u001b[39m.\u001b[39mabs(x_re[:, np\u001b[39m.\u001b[39mnewaxis] \u001b[39m-\u001b[39m x_re[np\u001b[39m.\u001b[39mnewaxis, :]), axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m r,\n\u001b[0;32m   1786\u001b[0m         axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m   1787\u001b[0m     ) \u001b[39m/\u001b[39m (N \u001b[39m-\u001b[39m m \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m   1788\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mlog(C)) \u001b[39m/\u001b[39m (N \u001b[39m-\u001b[39m m \u001b[39m+\u001b[39m \u001b[39m1.0\u001b[39m)\n\u001b[1;32m-> 1790\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mabs(_phi(m) \u001b[39m-\u001b[39m _phi(m \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tsfresh\\feature_extraction\\feature_calculators.py:1785\u001b[0m, in \u001b[0;36m_phi\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_phi\u001b[39m(m):\n\u001b[0;32m   1783\u001b[0m     x_re \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([x[i : i \u001b[39m+\u001b[39m m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N \u001b[39m-\u001b[39m m \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)])\n\u001b[0;32m   1784\u001b[0m     C \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(\n\u001b[1;32m-> 1785\u001b[0m         np\u001b[39m.\u001b[39mmax(np\u001b[39m.\u001b[39mabs(x_re[:, np\u001b[39m.\u001b[39mnewaxis] \u001b[39m-\u001b[39m x_re[np\u001b[39m.\u001b[39mnewaxis, :]), axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m r,\n\u001b[0;32m   1786\u001b[0m         axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m   1787\u001b[0m     ) \u001b[39m/\u001b[39m (N \u001b[39m-\u001b[39m m \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m   1788\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mlog(C)) \u001b[39m/\u001b[39m (N \u001b[39m-\u001b[39m m \u001b[39m+\u001b[39m \u001b[39m1.0\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.45 GiB for an array with shape (17279, 17279, 2) and data type float64"
     ]
    }
   ],
   "source": [
    "# Extract features using tsfresh\n",
    "extraction_settings = ComprehensiveFCParameters()\n",
    "extracted_features = extract_features(long_data, column_id=\"id\", column_sort=\"time\", column_kind=\"attribute\", column_value=\"value\", default_fc_parameters=extraction_settings)\n",
    "\n",
    "# Impute missing values in the extracted features\n",
    "imputed_features = impute(extracted_features)\n",
    "\n",
    "# Merge the extracted features with the original dataset\n",
    "final_data = data.merge(imputed_features, on=\"id\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
